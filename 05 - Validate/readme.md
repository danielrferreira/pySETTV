# Validate Models
After creating a model, the next crucial question is: how well does it predict your outcome? These code snippets are designed to help you evaluate model performance from multiple perspectives, enabling a more holistic understanding of its effectiveness. Additionally, some business cases require customized metrics, such as expected profit or the cost assessment of specific actions, which are not considered here.
- [Fit Statistics & Graphs for Quantitative Outcome](https://github.com/danielrferreira/pySETTV/tree/main/05%20-%20Validate/Quantitative)
- [Fit Statistics & Graphs for Categorical Outcome](https://github.com/danielrferreira/pySETTV/tree/main/05%20-%20Validate/Classification)
- [Linear Regressions Assumptions Check](https://github.com/danielrferreira/pySETTV/tree/main/05%20-%20Validate/Linear%20Regression%20Assumptions)
- [Model Comparison](https://github.com/danielrferreira/pySETTV/tree/main/05%20-%20Validate/Model%20Comparison)
- [Cross-Validation](https://github.com/danielrferreira/pySETTV/tree/main/05%20-%20Validate/Cross%20Validation)
